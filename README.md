# ðŸŽ§ðŸ”µ Soundâ€“Shape Crossmodal Correspondence Experiment

This repository contains the full implementation and audio material for an interactive web-based experiment exploring how people intuitively associate **sound textures** with **visual shape morphologies**.  

<p align="center">
  <img src="UI_example.png" alt="UI screenshot of the experiment" width="600">
</p>

Participants listen to short sound clips and adjust a shape via a sliderâ€”from smooth to rough to sharpâ€”based on how they perceive each sound.

<p align="center">
  <img src="shape_morphing_selection.png" alt="UI screenshot of the experiment" width="600">
</p>
---

## ðŸ“Œ Overview

- **Research area**: Cross-modal perception, auditory-visual correspondences, sound texture
- **Method**: Browser-based interface using HTML5 + JavaScript + FastAPI (python)
- **Data collected**: Shape selection (slider value), demographic info (music experience, listening equipment)


